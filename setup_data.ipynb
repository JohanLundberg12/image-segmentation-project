{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cc3c1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e3c285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./archive/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcdf1c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to check whether moving of images and data augmentations preserved \n",
    "# the number of images etc.\n",
    "\n",
    "def walk_through_dir(path: str):\n",
    "    dir_tree_generator = os.walk(path)\n",
    "    dirpath, dirnames, filenames = next(dir_tree_generator)\n",
    "    print(\"Root folder: \", dirpath)\n",
    "    print(\"It has {} subfolders and {} images\".format(len(dirnames), len(filenames)))\n",
    "    print()\n",
    "    \n",
    "    for dirpath, dirnames, filenames in dir_tree_generator:\n",
    "        print(\"This is a folder: \", dirpath)\n",
    "        print(\"It has {} subfolders and {} images\".format(len(dirnames), len(filenames)))\n",
    "        label = os.path.basename(dirpath)\n",
    "        print(\"Class: \", label, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34c3eaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root folder:  ./train\n",
      "It has 0 subfolders and 8242 images\n",
      "\n",
      "Root folder:  ./val\n",
      "It has 0 subfolders and 2345 images\n",
      "\n",
      "Root folder:  ./test\n",
      "It has 0 subfolders and 1155 images\n",
      "\n"
     ]
    }
   ],
   "source": [
    "walk_through_dir(\"./train\")\n",
    "walk_through_dir(\"./val\")\n",
    "walk_through_dir(\"./test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c938b68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root folder:  ./archive/\n",
      "It has 19 subfolders and 0 images\n",
      "\n",
      "This is a folder:  ./archive/Corals\n",
      "It has 0 subfolders and 500 images\n",
      "Class:  Corals \n",
      "\n",
      "This is a folder:  ./archive/Crabs\n",
      "It has 0 subfolders and 499 images\n",
      "Class:  Crabs \n",
      "\n",
      "This is a folder:  ./archive/Dolphin\n",
      "It has 0 subfolders and 782 images\n",
      "Class:  Dolphin \n",
      "\n",
      "This is a folder:  ./archive/Eel\n",
      "It has 0 subfolders and 497 images\n",
      "Class:  Eel \n",
      "\n",
      "This is a folder:  ./archive/Jelly Fish\n",
      "It has 0 subfolders and 855 images\n",
      "Class:  Jelly Fish \n",
      "\n",
      "This is a folder:  ./archive/Lobster\n",
      "It has 0 subfolders and 499 images\n",
      "Class:  Lobster \n",
      "\n",
      "This is a folder:  ./archive/Nudibranchs\n",
      "It has 0 subfolders and 500 images\n",
      "Class:  Nudibranchs \n",
      "\n",
      "This is a folder:  ./archive/Octopus\n",
      "It has 0 subfolders and 562 images\n",
      "Class:  Octopus \n",
      "\n",
      "This is a folder:  ./archive/Penguin\n",
      "It has 0 subfolders and 482 images\n",
      "Class:  Penguin \n",
      "\n",
      "This is a folder:  ./archive/Puffers\n",
      "It has 0 subfolders and 531 images\n",
      "Class:  Puffers \n",
      "\n",
      "This is a folder:  ./archive/Sea Rays\n",
      "It has 0 subfolders and 517 images\n",
      "Class:  Sea Rays \n",
      "\n",
      "This is a folder:  ./archive/Sea Urchins\n",
      "It has 0 subfolders and 579 images\n",
      "Class:  Sea Urchins \n",
      "\n",
      "This is a folder:  ./archive/Seahorse\n",
      "It has 0 subfolders and 478 images\n",
      "Class:  Seahorse \n",
      "\n",
      "This is a folder:  ./archive/Seal\n",
      "It has 0 subfolders and 414 images\n",
      "Class:  Seal \n",
      "\n",
      "This is a folder:  ./archive/Sharks\n",
      "It has 0 subfolders and 590 images\n",
      "Class:  Sharks \n",
      "\n",
      "This is a folder:  ./archive/Squid\n",
      "It has 0 subfolders and 483 images\n",
      "Class:  Squid \n",
      "\n",
      "This is a folder:  ./archive/Starfish\n",
      "It has 0 subfolders and 499 images\n",
      "Class:  Starfish \n",
      "\n",
      "This is a folder:  ./archive/Turtle_Tortoise\n",
      "It has 0 subfolders and 1903 images\n",
      "Class:  Turtle_Tortoise \n",
      "\n",
      "This is a folder:  ./archive/Whale\n",
      "It has 0 subfolders and 572 images\n",
      "Class:  Whale \n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(walk_through_dir(\"./archive/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46564812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To move images to train, val and test folders while also renaming them\n",
    "\n",
    "def create_train_val_test_folders(root_path: str):\n",
    "    \"\"\"Given a folder structure:\n",
    "                root_folder:\n",
    "                    - subfolder_1:\n",
    "                        -img_11\n",
    "                        -img_2\n",
    "                        ...\n",
    "                        -img_n\n",
    "                    - subfolder_2:\n",
    "                    ...\n",
    "                    - subfolder_n\n",
    "        this function creates a train, val, test folder \n",
    "        outside the root folder and moves the images to these\n",
    "        folders randomly. An image is renamed to include its original label\n",
    "        which was the original subfolder name. An extension _00 is added\n",
    "        to indicate no data augmentation in case data augmentation will used later. \n",
    "    \"\"\"\n",
    "    root_path = Path(root_path)\n",
    "    os.makedirs(\"train\", exist_ok=True)\n",
    "    os.makedirs(\"val\", exist_ok=True)\n",
    "    os.makedirs(\"test\", exist_ok=True)\n",
    "    \n",
    "    dir_tree_generator = os.walk(root_path)\n",
    "    dirpath, dirnames, filenames = next(dir_tree_generator)\n",
    "    \n",
    "    for dirpath, dirnames, filenames in dir_tree_generator:\n",
    "        label = os.path.basename(dirpath)\n",
    "        subfolder = path / Path(label)\n",
    "        \n",
    "        for original_filename in filenames:\n",
    "            filename, ext = os.path.splitext(original_filename)\n",
    "            new_filename = filename + \"_\" + label + \"_00\" + ext #00 for original\n",
    "            \n",
    "            n = np.random.random()\n",
    "            if n < 0.1:\n",
    "                os.rename(subfolder / original_filename, Path(\"test\") / new_filename)\n",
    "            elif n < 0.3:\n",
    "                os.rename(subfolder / original_filename, Path(\"val\") / new_filename)\n",
    "            else:\n",
    "                os.rename(subfolder / original_filename, Path(\"train\") / new_filename)\n",
    "            \n",
    "            \n",
    "            \n",
    "#create_train_val_test_folders(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97a52d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper dataset opener and helper function\n",
    "\n",
    "def _get_name(path: str):\n",
    "    name, ext = os.path.splitext(path.split(\"_\")[-2])\n",
    "    \n",
    "    return name\n",
    "\n",
    "class SeaAnimalsDataset_Open:\n",
    "    \"\"\"Dataset class used to open images. \n",
    "    This is merely used later to do data augmentation. \n",
    "    \"\"\"\n",
    "    def __init__(self, imgs_path, transform):\n",
    "        self.imgs_path = imgs_path\n",
    "        self.transform = transform\n",
    "        self.imgs = os.listdir(self.imgs_path)\n",
    "        self.labels = list(map(lambda img_path: _get_name(img_path), self.imgs))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.imgs_path, self.imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        image_out = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return image_out, label, self.imgs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b245b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (128, 128)\n",
    "transformation = transforms.Compose([transforms.Resize(input_size)])\n",
    "sea_animals = SeaAnimalsDataset_Open(\"train\", transform=transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a700211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining all transformations\n",
    "# Defining endings and augmentation\n",
    "\n",
    "# _00: original data\n",
    "# _01: horizontal transformation\n",
    "# _02: shape transformation (resize and crop)\n",
    "# _03: brightness transformation\n",
    "# _04: contrast transformation\n",
    "# _05: gaussian noise\n",
    "# _06: total: all transformations\n",
    "\n",
    "aug_horizontal = transforms.RandomHorizontalFlip(p = 1)\n",
    "\n",
    "shape_aug = transforms.RandomResizedCrop(\n",
    "    (128, 128), scale=(0.1, 0.9), ratio=(0.5,2))\n",
    "\n",
    "brightness_aug = transforms.ColorJitter(brightness=0.5, contrast=0,\n",
    "                                       saturation=0, hue=0)\n",
    "\n",
    "contrast_aug = transforms.ColorJitter(brightness=0, contrast=0.5, saturation=0.2,\n",
    "                                       hue=0.1)\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=0.001):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "\n",
    "transform_gaussian=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0,1),\n",
    "    AddGaussianNoise(0., 0.001), #Change 0.001 to be a higher number of we need more noise - shall also be done in the AddGaussia\n",
    "    transforms.ToPILImage()\n",
    "])\n",
    "\n",
    "total_aug_data = transforms.Compose([\n",
    "    aug_horizontal, shape_aug, brightness_aug, contrast_aug, transform_gaussian])\n",
    "\n",
    "total_aug_labels = transforms.Compose([\n",
    "    aug_horizontal, shape_aug]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789ab170",
   "metadata": {},
   "source": [
    "    Below we create the folder train_augment which will contain original images and the augmented versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e93529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_augment = \"./train_augment/\"\n",
    "os.makedirs(path_augment, exist_ok=True)\n",
    "\n",
    "for i in range(len(sea_animals)):\n",
    "    # Define current image and labels\n",
    "    img = sea_animals[i][0]\n",
    "    label = sea_animals[i][1]\n",
    "    img_name = sea_animals[i][2]\n",
    "    name, ext = os.path.splitext(img_name)\n",
    "    \n",
    "    # Save original img\n",
    "    img.save(path_augment+name+ext)\n",
    "\n",
    "    # Horizontal flip\n",
    "    img_flip = aug_horizontal(img)\n",
    "    img_flip.save(path_augment+name[:-3]+\"_01\"+ext) #ext=.jpg, .png etc.\n",
    "    \n",
    "    # Crop and resize\n",
    "    rand_1 = np.random.randint(1000)\n",
    "    torch.manual_seed(rand_1)\n",
    "    img_crop = shape_aug(img)\n",
    "    img_crop.save(path_augment+name[:-3]+\"_02\"+ext)\n",
    "    \n",
    "    # Brightness\n",
    "    img_bright = brightness_aug(img)\n",
    "    img_bright.save(path_augment+name[:-3]+\"_03\"+ext)\n",
    "\n",
    "    # Colour and saturation\n",
    "    img_contrast = contrast_aug(img)\n",
    "    img_contrast.save(path_augment+name[:-3]+\"_04\"+ext)\n",
    "\n",
    "    # Gaussian noise\n",
    "    img_gaussian = transform_gaussian(img)\n",
    "    img_gaussian.save(path_augment+name[:-3]+\"_05\"+ext)\n",
    "\n",
    "    # Combined augmentation\n",
    "    rand_2 = np.random.randint(1000)\n",
    "    torch.manual_seed(rand_2)\n",
    "    img_combined = total_aug_data(img)\n",
    "    img_combined.save(path_augment+name[:-3]+\"_06\"+ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190bcc4a",
   "metadata": {},
   "source": [
    "    Finally, the SeaAnimalsDataset class we will use during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0663d247",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeaAnimalsDataset:\n",
    "\n",
    "    def __init__(self, img_path, transform,\n",
    "                 train: bool = True, augmentations: List[str] = ['00']):\n",
    "        self.img_path = img_path\n",
    "        self.transform = transform\n",
    "        self.total_imgs = os.listdir(self.img_path)\n",
    "\n",
    "        if train:\n",
    "            self.total_imgs = [\n",
    "                img_path for img_path in self.total_imgs if img_path[-6:-4] in augmentations]\n",
    "        self.total_labels = list(map(lambda img_path: _get_name(img_path), self.total_imgs))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.img_path, self.total_imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        label = self.total_labels[idx]\n",
    "        out_image = self.transform(image)\n",
    "        out_image = transforms.Compose([transforms.ToTensor()])(out_image)\n",
    "\n",
    "        return out_image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11ea441",
   "metadata": {},
   "source": [
    "    test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8815de54",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = ['00']\n",
    "train_imgs_path = 'train_augment'\n",
    "sea_animals_train = SeaAnimalsDataset(\n",
    "        img_path=train_imgs_path,\n",
    "        transform=transformation,\n",
    "        train=True,\n",
    "        augmentations=augmentations)\n",
    "sea_animals_val = SeaAnimalsDataset(\n",
    "    img_path=\"val\",\n",
    "    transform=transformation,\n",
    "    train=False)\n",
    "sea_animals_test = SeaAnimalsDataset(\n",
    "    img_path=\"test\",\n",
    "    transform=transformation,\n",
    "    train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b737d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(sea_animals_train, batch_size=1, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(sea_animals_val, batch_size=1, shuffle=True, drop_last=False)\n",
    "test_loader = DataLoader(sea_animals_test, batch_size=1, shuffle=True, drop_last=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
